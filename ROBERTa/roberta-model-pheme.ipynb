{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4159888,"sourceType":"datasetVersion","datasetId":2455636}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T17:27:14.409772Z","iopub.execute_input":"2024-11-06T17:27:14.410193Z","iopub.status.idle":"2024-11-06T17:27:15.531072Z","shell.execute_reply.started":"2024-11-06T17:27:14.410152Z","shell.execute_reply":"2024-11-06T17:27:15.529807Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pheme-dataset-for-rumour-detection/dataset.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing the packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm  # For progress bar\nfrom torch.cuda.amp import autocast, GradScaler\nimport gc\n\n# Set GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:24.359804Z","iopub.execute_input":"2024-11-06T17:27:24.361853Z","iopub.status.idle":"2024-11-06T17:27:30.958174Z","shell.execute_reply.started":"2024-11-06T17:27:24.361771Z","shell.execute_reply":"2024-11-06T17:27:30.957095Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/pheme-dataset-for-rumour-detection/dataset.csv')\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:36.967383Z","iopub.execute_input":"2024-11-06T17:27:36.968047Z","iopub.status.idle":"2024-11-06T17:27:37.341131Z","shell.execute_reply.started":"2024-11-06T17:27:36.967980Z","shell.execute_reply":"2024-11-06T17:27:37.340056Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                    text  is_rumor  \\\n0      Charlie Hebdo became well known for publishing...       0.0   \n1      Now 10 dead in a shooting there today RT \"@BBC...       0.0   \n2      @BBCDanielS @BBCWorld I'm guessing this is bei...       0.0   \n3      @BBCDanielS @BBCWorld why would you mention th...       0.0   \n4                @BBCDanielS @BBCWorld perps identified?       0.0   \n...                                                  ...       ...   \n62440  @AnonyOps @Xplant So that means its ok to torc...       1.0   \n62441  @RianAlden not at all, but they need to change...       1.0   \n62442  @Xplant @AnonyOps Absoluteky.  But it pains me...       1.0   \n62443  @Xplant @AnonyOps I'm curious how many of thes...       1.0   \n62444  @Xplant @AnonyOps You get 15,000 people showin...       1.0   \n\n         user.handle         topic  \n0         BBCDanielS  charliehebdo  \n1          robbylevy  charliehebdo  \n2      ModerateInAll  charliehebdo  \n3        GabTarquini  charliehebdo  \n4      freethought41  charliehebdo  \n...              ...           ...  \n62440      RianAlden      ferguson  \n62441         Xplant      ferguson  \n62442      RianAlden      ferguson  \n62443      RianAlden      ferguson  \n62444      RianAlden      ferguson  \n\n[62445 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>is_rumor</th>\n      <th>user.handle</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Charlie Hebdo became well known for publishing...</td>\n      <td>0.0</td>\n      <td>BBCDanielS</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now 10 dead in a shooting there today RT \"@BBC...</td>\n      <td>0.0</td>\n      <td>robbylevy</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@BBCDanielS @BBCWorld I'm guessing this is bei...</td>\n      <td>0.0</td>\n      <td>ModerateInAll</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@BBCDanielS @BBCWorld why would you mention th...</td>\n      <td>0.0</td>\n      <td>GabTarquini</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@BBCDanielS @BBCWorld perps identified?</td>\n      <td>0.0</td>\n      <td>freethought41</td>\n      <td>charliehebdo</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62440</th>\n      <td>@AnonyOps @Xplant So that means its ok to torc...</td>\n      <td>1.0</td>\n      <td>RianAlden</td>\n      <td>ferguson</td>\n    </tr>\n    <tr>\n      <th>62441</th>\n      <td>@RianAlden not at all, but they need to change...</td>\n      <td>1.0</td>\n      <td>Xplant</td>\n      <td>ferguson</td>\n    </tr>\n    <tr>\n      <th>62442</th>\n      <td>@Xplant @AnonyOps Absoluteky.  But it pains me...</td>\n      <td>1.0</td>\n      <td>RianAlden</td>\n      <td>ferguson</td>\n    </tr>\n    <tr>\n      <th>62443</th>\n      <td>@Xplant @AnonyOps I'm curious how many of thes...</td>\n      <td>1.0</td>\n      <td>RianAlden</td>\n      <td>ferguson</td>\n    </tr>\n    <tr>\n      <th>62444</th>\n      <td>@Xplant @AnonyOps You get 15,000 people showin...</td>\n      <td>1.0</td>\n      <td>RianAlden</td>\n      <td>ferguson</td>\n    </tr>\n  </tbody>\n</table>\n<p>62445 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"dataset.rename(columns={'is_rumor': 'label'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:45.549819Z","iopub.execute_input":"2024-11-06T17:27:45.550273Z","iopub.status.idle":"2024-11-06T17:27:45.556205Z","shell.execute_reply.started":"2024-11-06T17:27:45.550231Z","shell.execute_reply":"2024-11-06T17:27:45.555107Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(dataset['label'].value_counts(), '\\n')\nprint(dataset.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:47.597763Z","iopub.execute_input":"2024-11-06T17:27:47.598437Z","iopub.status.idle":"2024-11-06T17:27:47.633554Z","shell.execute_reply.started":"2024-11-06T17:27:47.598396Z","shell.execute_reply":"2024-11-06T17:27:47.632411Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"label\n0.0    48619\n1.0    13824\nName: count, dtype: int64 \n\ntext               0\nlabel              2\nuser.handle        2\ntopic          12777\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:50.964828Z","iopub.execute_input":"2024-11-06T17:27:50.965923Z","iopub.status.idle":"2024-11-06T17:27:50.998940Z","shell.execute_reply.started":"2024-11-06T17:27:50.965875Z","shell.execute_reply":"2024-11-06T17:27:50.997634Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"label_0 = dataset[dataset['label'] == 0].sample(n=8000, random_state=42)\nlabel_1 = dataset[dataset['label'] == 1]\ndataset = pd.concat([label_0, label_1], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:27:55.869712Z","iopub.execute_input":"2024-11-06T17:27:55.870637Z","iopub.status.idle":"2024-11-06T17:27:55.892188Z","shell.execute_reply.started":"2024-11-06T17:27:55.870580Z","shell.execute_reply":"2024-11-06T17:27:55.890839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset['statement'] = 'text: ' + dataset['text'] + ' user_handle: ' + dataset['user.handle'] + ' topic: ' + dataset['topic']\ndataset.drop(['text', 'user.handle', 'topic'], axis=1, inplace=True)\ndataset = dataset[['statement', 'label']]\ndataset.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:04.230501Z","iopub.execute_input":"2024-11-06T17:28:04.230933Z","iopub.status.idle":"2024-11-06T17:28:04.258708Z","shell.execute_reply.started":"2024-11-06T17:28:04.230892Z","shell.execute_reply":"2024-11-06T17:28:04.257452Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset['label'] = dataset['label'].astype('int64')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:06.402975Z","iopub.execute_input":"2024-11-06T17:28:06.403346Z","iopub.status.idle":"2024-11-06T17:28:06.409458Z","shell.execute_reply.started":"2024-11-06T17:28:06.403313Z","shell.execute_reply":"2024-11-06T17:28:06.408400Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization using ROBERTa tokenizer","metadata":{}},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n\nMAX_LEN = 256\n\ninput_ids_list = []\nattention_masks_list = []\n\nfor text in tqdm(dataset['statement'].values, desc=\"Tokenizing\", unit=\"text\"):\n    # Clear the GPU cache to free up memory\n    torch.cuda.empty_cache()\n    \n    # Run garbage collection\n#     gc.collect()\n    \n    encoded = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    \n    # Append results to lists\n    input_ids_list.append(encoded['input_ids'])\n    attention_masks_list.append(encoded['attention_mask'])\n\n# Convert lists to tensors and move to GPU if available\ninput_ids = torch.cat(input_ids_list).to(device)\nattention_masks = torch.cat(attention_masks_list).to(device)\nlabels = torch.tensor(dataset['label'].values).to(device)\n\nprint(\"Tokenization complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:08.593581Z","iopub.execute_input":"2024-11-06T17:28:08.593936Z","iopub.status.idle":"2024-11-06T17:28:22.303529Z","shell.execute_reply.started":"2024-11-06T17:28:08.593903Z","shell.execute_reply":"2024-11-06T17:28:22.302469Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35b69e1b3c5f4101899369da6977efa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b16668c296f4c0287b389969403f38b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb59d605c5f347289bcca98736007af6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81cd6024a8ef4533b568b9ca623daca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee70602d5a23415b9c474c8ee01183af"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nTokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14479/14479 [00:12<00:00, 1156.93text/s]\n","output_type":"stream"},{"name":"stdout","text":"Tokenization complete!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train and Test split","metadata":{}},{"cell_type":"code","source":"train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\ntrain_masks, val_masks, _, _ = train_test_split(attention_masks, labels, test_size=0.2, random_state=42)\n\n# Create DataLoader\nbatch_size = 8\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:24.588512Z","iopub.execute_input":"2024-11-06T17:28:24.588906Z","iopub.status.idle":"2024-11-06T17:28:24.644626Z","shell.execute_reply.started":"2024-11-06T17:28:24.588870Z","shell.execute_reply":"2024-11-06T17:28:24.643441Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning for ROBERTa Model","metadata":{}},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:27.518346Z","iopub.execute_input":"2024-11-06T17:28:27.519326Z","iopub.status.idle":"2024-11-06T17:28:27.526360Z","shell.execute_reply.started":"2024-11-06T17:28:27.519283Z","shell.execute_reply":"2024-11-06T17:28:27.525279Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\n    'roberta-base', \n    num_labels=2,\n    output_attentions=False,\n    output_hidden_states=False\n)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:29.928422Z","iopub.execute_input":"2024-11-06T17:28:29.928826Z","iopub.status.idle":"2024-11-06T17:28:33.196822Z","shell.execute_reply.started":"2024-11-06T17:28:29.928787Z","shell.execute_reply":"2024-11-06T17:28:33.195694Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5282bd5515774be2a43247021307d29d"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n\nepochs = 3\ntotal_steps = len(train_dataloader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:36.759979Z","iopub.execute_input":"2024-11-06T17:28:36.760371Z","iopub.status.idle":"2024-11-06T17:28:37.298890Z","shell.execute_reply.started":"2024-11-06T17:28:36.760336Z","shell.execute_reply":"2024-11-06T17:28:37.297773Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Training and visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:40.607579Z","iopub.execute_input":"2024-11-06T17:28:40.608471Z","iopub.status.idle":"2024-11-06T17:28:40.623378Z","shell.execute_reply.started":"2024-11-06T17:28:40.608425Z","shell.execute_reply":"2024-11-06T17:28:40.621996Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:40.984235Z","iopub.execute_input":"2024-11-06T17:28:40.984645Z","iopub.status.idle":"2024-11-06T17:28:40.989497Z","shell.execute_reply.started":"2024-11-06T17:28:40.984604Z","shell.execute_reply":"2024-11-06T17:28:40.988432Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"scaler = GradScaler()  # For mixed precision\naccumulation_steps = 4  # Number of steps for gradient accumulation\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    model.train()\n\n    total_loss = 0\n    correct_predictions = 0\n    total_train = 0\n\n    # Create a single progress bar\n    pbar = tqdm(total=len(train_dataloader), desc=\"Training\")\n    \n    for step, batch in enumerate(train_dataloader):\n        torch.cuda.empty_cache()\n        \n        batch = tuple(b.to(device) for b in batch)\n        inputs, masks, labels = batch\n        \n        # Enable autocasting for mixed precision\n        with autocast():\n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)  # Updated for RoBERTa\n            loss = outputs.loss\n            \n        # Accumulate gradients\n        total_loss += loss.item()\n\n        # Calculate training accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        correct_predictions += (predictions == labels).sum().item()\n        total_train += labels.size(0)\n\n        # Scale the loss and call backward() to create the gradients\n        scaler.scale(loss).backward()\n        \n        # Update weights after accumulating gradients\n        if (step + 1) % accumulation_steps == 0:\n            # Clip gradients\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()  # Clear gradients for the next step\n\n        # Update progress bar\n        pbar.update(1)  # Increment progress bar\n\n    pbar.close()  # Close the progress bar after training\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    avg_train_accuracy = correct_predictions / total_train\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(avg_train_accuracy)\n\n    print(f'Average training loss: {avg_train_loss:.2f}')\n    print(f'Training accuracy: {avg_train_accuracy:.2f}')\n    \n    model.eval()\n    eval_loss = 0\n    correct_predictions_val = 0\n    total_val = 0\n    predictions_all = []\n    true_labels_all = []\n\n    # Evaluate without gradient tracking\n    for batch in val_dataloader:\n        batch = tuple(b.to(device) for b in batch)\n        inputs, masks, labels = batch\n\n        with torch.no_grad():\n            # Pass labels for loss calculation\n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels) \n\n        logits = outputs.logits\n        eval_loss += outputs.loss.item() \n\n        # Calculate validation accuracy\n        predictions = torch.argmax(logits, dim=-1)\n        correct_predictions_val += (predictions == labels).sum().item()\n        total_val += labels.size(0)\n\n        predictions_all.extend(predictions.cpu().numpy())\n        true_labels_all.extend(labels.cpu().numpy())\n\n    avg_val_loss = eval_loss / len(val_dataloader)\n    avg_val_accuracy = correct_predictions_val / total_val\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(avg_val_accuracy)\n\n    print(f'Validation Loss: {avg_val_loss:.2f}')\n    print(f'Validation Accuracy: {avg_val_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:28:43.214166Z","iopub.execute_input":"2024-11-06T17:28:43.214835Z","iopub.status.idle":"2024-11-06T17:46:26.011723Z","shell.execute_reply.started":"2024-11-06T17:28:43.214795Z","shell.execute_reply":"2024-11-06T17:46:26.010632Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/512028132.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # For mixed precision\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1448 [00:00<?, ?it/s]/tmp/ipykernel_30/512028132.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nTraining: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1448/1448 [05:34<00:00,  4.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.48\nTraining accuracy: 0.72\nValidation Loss: 0.32\nValidation Accuracy: 0.85\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1448/1448 [05:33<00:00,  4.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.29\nTraining accuracy: 0.87\nValidation Loss: 0.22\nValidation Accuracy: 0.91\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1448/1448 [05:34<00:00,  4.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.19\nTraining accuracy: 0.92\nValidation Loss: 0.20\nValidation Accuracy: 0.92\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# After the training loop, calculate other metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels_all, predictions_all))\n\n# Calculate ROC-AUC score if the task is binary classification\nroc_auc = roc_auc_score(true_labels_all, predictions_all)\nprint(f'ROC-AUC Score: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:46:42.587290Z","iopub.execute_input":"2024-11-06T17:46:42.587712Z","iopub.status.idle":"2024-11-06T17:46:42.618629Z","shell.execute_reply.started":"2024-11-06T17:46:42.587651Z","shell.execute_reply":"2024-11-06T17:46:42.617462Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93      1594\n           1       0.91      0.91      0.91      1302\n\n    accuracy                           0.92      2896\n   macro avg       0.92      0.92      0.92      2896\nweighted avg       0.92      0.92      0.92      2896\n\nROC-AUC Score: 0.92\n","output_type":"stream"}]},{"cell_type":"code","source":"fig = go.Figure()\n\n# Loss\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_losses, mode='lines+markers', name='Training Loss'))\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_losses, mode='lines+markers', name='Validation Loss'))\n\n# Accuracy\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_accuracies, mode='lines+markers', name='Training Accuracy'))\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_accuracies, mode='lines+markers', name='Validation Accuracy'))\n\n# Update layout\nfig.update_layout(\n    title='Training and Validation Loss and Accuracy',\n    xaxis_title='Epochs',\n    yaxis_title='Loss / Accuracy',\n    legend_title='Metrics'\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:46:47.483486Z","iopub.execute_input":"2024-11-06T17:46:47.484468Z","iopub.status.idle":"2024-11-06T17:46:47.923658Z","shell.execute_reply.started":"2024-11-06T17:46:47.484422Z","shell.execute_reply":"2024-11-06T17:46:47.922736Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"8e6a1a13-12e7-4532-bda0-971ad0224de5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8e6a1a13-12e7-4532-bda0-971ad0224de5\")) {                    Plotly.newPlot(                        \"8e6a1a13-12e7-4532-bda0-971ad0224de5\",                        [{\"mode\":\"lines+markers\",\"name\":\"Training Loss\",\"x\":[1,2,3],\"y\":[0.4841388901129612,0.2909723984139318,0.18559788942892744],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[1,2,3],\"y\":[0.31953061703407304,0.22122180535977717,0.20152574543872057],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Training Accuracy\",\"x\":[1,2,3],\"y\":[0.7214020547353881,0.8687732021065354,0.9236812570145904],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3],\"y\":[0.8539364640883977,0.9084944751381215,0.9219613259668509],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training and Validation Loss and Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss \\u002f Accuracy\"}},\"legend\":{\"title\":{\"text\":\"Metrics\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8e6a1a13-12e7-4532-bda0-971ad0224de5');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\nsave_directory = \"/kaggle/working/roberta-pheme\"\nos.makedirs(save_directory, exist_ok=True)\n\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\n\nzip_file_path = \"/kaggle/working/roberta-pheme.zip\"\nshutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:48:46.104682Z","iopub.execute_input":"2024-11-06T17:48:46.105744Z","iopub.status.idle":"2024-11-06T17:49:29.981865Z","shell.execute_reply.started":"2024-11-06T17:48:46.105696Z","shell.execute_reply":"2024-11-06T17:49:29.980863Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/roberta-pheme.zip'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}