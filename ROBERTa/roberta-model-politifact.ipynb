{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9561382,"sourceType":"datasetVersion","datasetId":5826660}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T17:56:48.833002Z","iopub.execute_input":"2024-11-06T17:56:48.833389Z","iopub.status.idle":"2024-11-06T17:56:49.834108Z","shell.execute_reply.started":"2024-11-06T17:56:48.833335Z","shell.execute_reply":"2024-11-06T17:56:49.833164Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/politifact-dataset-for-fake-news-detection/politifact_real.csv\n/kaggle/input/politifact-dataset-for-fake-news-detection/politifact_fake.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing the relevant packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm \nfrom torch.cuda.amp import autocast, GradScaler\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:05.335094Z","iopub.execute_input":"2024-11-06T17:57:05.335600Z","iopub.status.idle":"2024-11-06T17:57:11.320526Z","shell.execute_reply.started":"2024-11-06T17:57:05.335560Z","shell.execute_reply":"2024-11-06T17:57:11.319543Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing the dataset","metadata":{}},{"cell_type":"code","source":"true = pd.read_csv('/kaggle/input/politifact-dataset-for-fake-news-detection/politifact_real.csv')\nfake = pd.read_csv('/kaggle/input/politifact-dataset-for-fake-news-detection/politifact_fake.csv')\n\n# Add labels: 1 for fake, 0 for true\ntrue['label'] = 0\nfake['label'] = 1\n\ndataset = pd.concat([true, fake], axis=0, ignore_index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:18.819395Z","iopub.execute_input":"2024-11-06T17:57:18.820405Z","iopub.status.idle":"2024-11-06T17:57:19.136336Z","shell.execute_reply.started":"2024-11-06T17:57:18.820363Z","shell.execute_reply":"2024-11-06T17:57:19.135535Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"print(dataset.isna().sum(), '\\n')\nprint(dataset['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:21.491750Z","iopub.execute_input":"2024-11-06T17:57:21.492123Z","iopub.status.idle":"2024-11-06T17:57:21.507728Z","shell.execute_reply.started":"2024-11-06T17:57:21.492088Z","shell.execute_reply":"2024-11-06T17:57:21.506725Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"id             0\nnews_url      61\ntitle          0\ntweet_ids    255\nlabel          0\ndtype: int64 \n\nlabel\n0    624\n1    432\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:23.720990Z","iopub.execute_input":"2024-11-06T17:57:23.721876Z","iopub.status.idle":"2024-11-06T17:57:23.730649Z","shell.execute_reply.started":"2024-11-06T17:57:23.721836Z","shell.execute_reply":"2024-11-06T17:57:23.729716Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset['statement'] = 'id: ' + dataset['id'] + ' news_url: ' + dataset['news_url'] + ' title: ' + dataset['title'] + ' tweet_ids: ' + dataset['tweet_ids']","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:25.628309Z","iopub.execute_input":"2024-11-06T17:57:25.629199Z","iopub.status.idle":"2024-11-06T17:57:25.645389Z","shell.execute_reply.started":"2024-11-06T17:57:25.629158Z","shell.execute_reply":"2024-11-06T17:57:25.644452Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset.drop(['id', 'news_url', 'title', 'tweet_ids'], axis=1, inplace=True)\ndataset = dataset[['statement', 'label']]\ndataset.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:27.137767Z","iopub.execute_input":"2024-11-06T17:57:27.138149Z","iopub.status.idle":"2024-11-06T17:57:27.146297Z","shell.execute_reply.started":"2024-11-06T17:57:27.138114Z","shell.execute_reply":"2024-11-06T17:57:27.145273Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization using ROBERTa tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-06T19:43:42.298597Z","iopub.execute_input":"2024-10-06T19:43:42.299321Z","iopub.status.idle":"2024-10-06T19:43:42.309843Z","shell.execute_reply.started":"2024-10-06T19:43:42.299281Z","shell.execute_reply":"2024-10-06T19:43:42.308867Z"}}},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n\nMAX_LEN = 256\n\ninput_ids_list = []\nattention_masks_list = []\n\nfor text in tqdm(dataset['statement'].values, desc=\"Tokenizing\", unit=\"text\"):\n    # Clear the GPU cache to free up memory\n    torch.cuda.empty_cache()\n    \n    # Run garbage collection\n#     gc.collect()\n    \n    encoded = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    \n    # Append results to lists\n    input_ids_list.append(encoded['input_ids'])\n    attention_masks_list.append(encoded['attention_mask'])\n\n# Convert lists to tensors and move to GPU if available\ninput_ids = torch.cat(input_ids_list).to(device)\nattention_masks = torch.cat(attention_masks_list).to(device)\nlabels = torch.tensor(dataset['label'].values).to(device)\n\nprint(\"Tokenization complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:57:30.543158Z","iopub.execute_input":"2024-11-06T17:57:30.543864Z","iopub.status.idle":"2024-11-06T17:59:03.398178Z","shell.execute_reply.started":"2024-11-06T17:57:30.543825Z","shell.execute_reply":"2024-11-06T17:59:03.397251Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c422265ff2d458fa97c6fe1e46a7f1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d19625bdad849dab67e78498cca24eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a35206208a274c359c7e380b8a0431d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2a28f65306450cb0a3622a112b6217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d7af9b665f94699955ae4313a83f6f8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nTokenizing: 100%|██████████| 762/762 [01:30<00:00,  8.40text/s]\n","output_type":"stream"},{"name":"stdout","text":"Tokenization complete!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train and Test split","metadata":{}},{"cell_type":"code","source":"train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\ntrain_masks, val_masks, _, _ = train_test_split(attention_masks, labels, test_size=0.2, random_state=42)\n\n# Create DataLoader\nbatch_size = 8\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:01:23.294383Z","iopub.execute_input":"2024-11-06T18:01:23.295032Z","iopub.status.idle":"2024-11-06T18:01:23.338919Z","shell.execute_reply.started":"2024-11-06T18:01:23.294993Z","shell.execute_reply":"2024-11-06T18:01:23.338212Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Fine tuning for ROBERTa Model","metadata":{}},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:59:48.427252Z","iopub.execute_input":"2024-11-06T17:59:48.428042Z","iopub.status.idle":"2024-11-06T17:59:48.435052Z","shell.execute_reply.started":"2024-11-06T17:59:48.427999Z","shell.execute_reply":"2024-11-06T17:59:48.434146Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\n    'roberta-base', \n    num_labels=2,\n    output_attentions=False,\n    output_hidden_states=False\n)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:59:50.252371Z","iopub.execute_input":"2024-11-06T17:59:50.252755Z","iopub.status.idle":"2024-11-06T18:00:11.034202Z","shell.execute_reply.started":"2024-11-06T17:59:50.252719Z","shell.execute_reply":"2024-11-06T18:00:11.033293Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b87f35889ccc43d3bc34c97c373fbaa0"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8, weight_decay=0.01)\n\nepochs = 10\ntotal_steps = len(train_dataloader) * epochs\n\nnum_warmup_steps = int(0.1 * total_steps)  # 10% of total steps\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:01:28.008808Z","iopub.execute_input":"2024-11-06T18:01:28.009687Z","iopub.status.idle":"2024-11-06T18:01:28.016409Z","shell.execute_reply.started":"2024-11-06T18:01:28.009646Z","shell.execute_reply":"2024-11-06T18:01:28.015418Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training and visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:01:30.182671Z","iopub.execute_input":"2024-11-06T18:01:30.183289Z","iopub.status.idle":"2024-11-06T18:01:30.195894Z","shell.execute_reply.started":"2024-11-06T18:01:30.183253Z","shell.execute_reply":"2024-11-06T18:01:30.194902Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:01:31.987066Z","iopub.execute_input":"2024-11-06T18:01:31.987751Z","iopub.status.idle":"2024-11-06T18:01:31.992014Z","shell.execute_reply.started":"2024-11-06T18:01:31.987714Z","shell.execute_reply":"2024-11-06T18:01:31.990907Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"scaler = GradScaler()  # For mixed precision\naccumulation_steps = 4  # Number of steps for gradient accumulation\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    model.train()\n\n    total_loss = 0\n    correct_predictions = 0\n    total_train = 0\n\n    # Create a single progress bar\n    pbar = tqdm(total=len(train_dataloader), desc=\"Training\")\n    \n    for step, batch in enumerate(train_dataloader):\n        torch.cuda.empty_cache()\n        \n        batch = tuple(b.to(device) for b in batch)\n        inputs, masks, labels = batch\n        \n        # Enable autocasting for mixed precision\n        with autocast():\n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)  # Updated for RoBERTa\n            loss = outputs.loss\n            \n        # Accumulate gradients\n        total_loss += loss.item()\n\n        # Calculate training accuracy\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n        correct_predictions += (predictions == labels).sum().item()\n        total_train += labels.size(0)\n\n        # Scale the loss and call backward() to create the gradients\n        scaler.scale(loss).backward()\n        \n        # Update weights after accumulating gradients\n        if (step + 1) % accumulation_steps == 0:\n            # Clip gradients\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()  # Clear gradients for the next step\n            scheduler.step()  # Step the scheduler\n\n        # Update progress bar\n        pbar.update(1)  # Increment progress bar\n\n    pbar.close()  # Close the progress bar after training\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    avg_train_accuracy = correct_predictions / total_train\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(avg_train_accuracy)\n\n    print(f'Average training loss: {avg_train_loss:.2f}')\n    print(f'Training accuracy: {avg_train_accuracy:.2f}')\n    \n    model.eval()\n    eval_loss = 0\n    correct_predictions_val = 0\n    total_val = 0\n    predictions_all = []\n    true_labels_all = []\n\n    # Evaluate without gradient tracking\n    for batch in val_dataloader:\n        batch = tuple(b.to(device) for b in batch)\n        inputs, masks, labels = batch\n\n        with torch.no_grad():\n            # Pass labels for loss calculation\n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels) \n\n        logits = outputs.logits\n        eval_loss += outputs.loss.item() \n\n        # Calculate validation accuracy\n        predictions = torch.argmax(logits, dim=-1)\n        correct_predictions_val += (predictions == labels).sum().item()\n        total_val += labels.size(0)\n\n        predictions_all.extend(predictions.cpu().numpy())\n        true_labels_all.extend(labels.cpu().numpy())\n\n    avg_val_loss = eval_loss / len(val_dataloader)\n    avg_val_accuracy = correct_predictions_val / total_val\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(avg_val_accuracy)\n\n    print(f'Validation Loss: {avg_val_loss:.2f}')\n    print(f'Validation Accuracy: {avg_val_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:01:41.764794Z","iopub.execute_input":"2024-11-06T18:01:41.765176Z","iopub.status.idle":"2024-11-06T18:03:44.627777Z","shell.execute_reply.started":"2024-11-06T18:01:41.765140Z","shell.execute_reply":"2024-11-06T18:03:44.626733Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/350650309.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # For mixed precision\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/77 [00:00<?, ?it/s]/tmp/ipykernel_30/350650309.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nTraining: 100%|██████████| 77/77 [00:10<00:00,  7.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.70\nTraining accuracy: 0.50\nValidation Loss: 0.69\nValidation Accuracy: 0.48\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:09<00:00,  7.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.68\nTraining accuracy: 0.59\nValidation Loss: 0.66\nValidation Accuracy: 0.52\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:09<00:00,  7.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.46\nTraining accuracy: 0.77\nValidation Loss: 0.28\nValidation Accuracy: 0.88\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:09<00:00,  7.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.20\nTraining accuracy: 0.93\nValidation Loss: 0.30\nValidation Accuracy: 0.87\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.15\nTraining accuracy: 0.94\nValidation Loss: 0.28\nValidation Accuracy: 0.88\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.07\nTraining accuracy: 0.98\nValidation Loss: 0.32\nValidation Accuracy: 0.92\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.06\nTraining accuracy: 0.98\nValidation Loss: 0.32\nValidation Accuracy: 0.94\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.08\nTraining accuracy: 0.98\nValidation Loss: 0.44\nValidation Accuracy: 0.91\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.05\nTraining accuracy: 0.99\nValidation Loss: 0.52\nValidation Accuracy: 0.91\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 77/77 [00:10<00:00,  7.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.03\nTraining accuracy: 1.00\nValidation Loss: 0.54\nValidation Accuracy: 0.92\n","output_type":"stream"}]},{"cell_type":"code","source":"# After the training loop, calculate other metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels_all, predictions_all))\n\n# Calculate ROC-AUC score if the task is binary classification\nroc_auc = roc_auc_score(true_labels_all, predictions_all)\nprint(f'ROC-AUC Score: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:03:50.230114Z","iopub.execute_input":"2024-11-06T18:03:50.230833Z","iopub.status.idle":"2024-11-06T18:03:50.251391Z","shell.execute_reply.started":"2024-11-06T18:03:50.230793Z","shell.execute_reply":"2024-11-06T18:03:50.250452Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.97      0.92        74\n           1       0.97      0.86      0.91        79\n\n    accuracy                           0.92       153\n   macro avg       0.92      0.92      0.91       153\nweighted avg       0.92      0.92      0.91       153\n\nROC-AUC Score: 0.92\n","output_type":"stream"}]},{"cell_type":"code","source":"fig = go.Figure()\n\n# Loss\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_losses, mode='lines+markers', name='Training Loss'))\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_losses, mode='lines+markers', name='Validation Loss'))\n\n# Accuracy\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=train_accuracies, mode='lines+markers', name='Training Accuracy'))\nfig.add_trace(go.Scatter(x=list(range(1, epochs + 1)), y=val_accuracies, mode='lines+markers', name='Validation Accuracy'))\n\n# Update layout\nfig.update_layout(\n    title='Training and Validation Loss and Accuracy',\n    xaxis_title='Epochs',\n    yaxis_title='Loss / Accuracy',\n    legend_title='Metrics'\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:03:59.093608Z","iopub.execute_input":"2024-11-06T18:03:59.094437Z","iopub.status.idle":"2024-11-06T18:03:59.509467Z","shell.execute_reply.started":"2024-11-06T18:03:59.094396Z","shell.execute_reply":"2024-11-06T18:03:59.508581Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"e31a7fcd-0eed-4a1a-9c3f-59275e3c1635\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e31a7fcd-0eed-4a1a-9c3f-59275e3c1635\")) {                    Plotly.newPlot(                        \"e31a7fcd-0eed-4a1a-9c3f-59275e3c1635\",                        [{\"mode\":\"lines+markers\",\"name\":\"Training Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.6966414018110796,0.6819398557984984,0.4615361597630885,0.20212883144230037,0.14574007554487747,0.06699427072103921,0.05842776577194016,0.07521116965776914,0.045962965140095006,0.025170929246134573],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.6906968265771866,0.6588759660720825,0.27926039360463617,0.30065330006182195,0.2804432027041912,0.3161522285081446,0.32123563993372956,0.44389768787368666,0.5190012295424822,0.543371897808538],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Training Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.49917898193760263,0.5894909688013136,0.7668308702791461,0.9293924466338259,0.9441707717569786,0.9786535303776683,0.9802955665024631,0.9819376026272578,0.9917898193760263,0.9950738916256158],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.48366013071895425,0.5163398692810458,0.8758169934640523,0.869281045751634,0.8823529411764706,0.9215686274509803,0.9411764705882353,0.9084967320261438,0.9084967320261438,0.9150326797385621],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training and Validation Loss and Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss \\u002f Accuracy\"}},\"legend\":{\"title\":{\"text\":\"Metrics\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('e31a7fcd-0eed-4a1a-9c3f-59275e3c1635');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\nsave_directory = \"/kaggle/working/roberta-politifact\"\nos.makedirs(save_directory, exist_ok=True)\n\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\n\nzip_file_path = \"/kaggle/working/roberta-politifact.zip\"\nshutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:06:12.012985Z","iopub.execute_input":"2024-11-06T18:06:12.013366Z","iopub.status.idle":"2024-11-06T18:06:56.672506Z","shell.execute_reply.started":"2024-11-06T18:06:12.013332Z","shell.execute_reply":"2024-11-06T18:06:56.671627Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/roberta-politifact.zip'"},"metadata":{}}]},{"cell_type":"code","source":"os.remove('/kaggle/working/robera-politifact.zip')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:07:54.665369Z","iopub.execute_input":"2024-11-06T18:07:54.666013Z","iopub.status.idle":"2024-11-06T18:07:54.672515Z","shell.execute_reply.started":"2024-11-06T18:07:54.665975Z","shell.execute_reply":"2024-11-06T18:07:54.671751Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-11-06T18:05:52.184091Z","iopub.execute_input":"2024-11-06T18:05:52.184486Z","iopub.status.idle":"2024-11-06T18:05:52.554212Z","shell.execute_reply.started":"2024-11-06T18:05:52.184447Z","shell.execute_reply":"2024-11-06T18:05:52.552841Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:725\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(fd)):\n\u001b[0;32m--> 725\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(fd)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:633\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    632\u001b[0m     err\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m--> 633\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:629\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rmtree_safe_fd\u001b[39m(topfd, path, onerror):\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopfd\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m scandir_it:\n\u001b[1;32m    630\u001b[0m             entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(scandir_it)\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/kaggle/working/robera-politifact.zip'"],"ename":"NotADirectoryError","evalue":"[Errno 20] Not a directory: '/kaggle/working/robera-politifact.zip'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}