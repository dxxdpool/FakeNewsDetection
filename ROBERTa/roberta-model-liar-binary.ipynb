{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9503349,"sourceType":"datasetVersion","datasetId":5783887}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-06T16:54:20.115377Z","iopub.execute_input":"2024-11-06T16:54:20.115667Z","iopub.status.idle":"2024-11-06T16:54:21.080624Z","shell.execute_reply.started":"2024-11-06T16:54:20.115635Z","shell.execute_reply":"2024-11-06T16:54:21.079449Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/liar-dataset/test.tsv\n/kaggle/input/liar-dataset/README\n/kaggle/input/liar-dataset/train.tsv\n/kaggle/input/liar-dataset/valid.tsv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing the packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm  # For progress bar\nfrom torch.cuda.amp import autocast, GradScaler\nimport gc\n\n# Set GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:54:26.522946Z","iopub.execute_input":"2024-11-06T16:54:26.523412Z","iopub.status.idle":"2024-11-06T16:54:32.290183Z","shell.execute_reply.started":"2024-11-06T16:54:26.523376Z","shell.execute_reply":"2024-11-06T16:54:32.289222Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing and preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/liar-dataset/train.tsv', delimiter='\\t')\ntest = pd.read_csv('/kaggle/input/liar-dataset/test.tsv', delimiter='\\t')\nvalid = pd.read_csv('/kaggle/input/liar-dataset/valid.tsv', delimiter='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:54:35.337052Z","iopub.execute_input":"2024-11-06T16:54:35.337587Z","iopub.status.idle":"2024-11-06T16:54:35.480404Z","shell.execute_reply.started":"2024-11-06T16:54:35.337545Z","shell.execute_reply":"2024-11-06T16:54:35.479585Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print('Train:\\n', train.isna().sum(), '\\n')\nprint('Test:\\n', test.isna().sum(), '\\n')\nprint('Valid:\\n', valid.isna().sum(), '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:54:40.904344Z","iopub.execute_input":"2024-11-06T16:54:40.904711Z","iopub.status.idle":"2024-11-06T16:54:40.928205Z","shell.execute_reply.started":"2024-11-06T16:54:40.904676Z","shell.execute_reply":"2024-11-06T16:54:40.927093Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Train:\n 2635.json                                                                                0\nfalse                                                                                    0\nSays the Annies List political group supports third-trimester abortions on demand.       0\nabortion                                                                                 2\ndwayne-bohac                                                                             2\nState representative                                                                  2898\nTexas                                                                                 2210\nrepublican                                                                               2\n0                                                                                        2\n1                                                                                        2\n0.1                                                                                      2\n0.2                                                                                      2\n0.3                                                                                      2\na mailer                                                                               102\ndtype: int64 \n\nTest:\n 11972.json                                                                0\ntrue                                                                      0\nBuilding a wall on the U.S.-Mexico border will take literally years.      0\nimmigration                                                               0\nrick-perry                                                                0\nGovernor                                                                325\nTexas                                                                   262\nrepublican                                                                0\n30                                                                        0\n30.1                                                                      0\n42                                                                        0\n23                                                                        0\n18                                                                        0\nRadio interview                                                          17\ndtype: int64 \n\nValid:\n 12134.json                                               0\nbarely-true                                              0\nWe have less Americans working now than in the 70s.      0\neconomy,jobs                                             0\nvicky-hartzler                                           0\nU.S. Representative                                    345\nMissouri                                               279\nrepublican                                               0\n1                                                        0\n0                                                        0\n1.1                                                      0\n0.1                                                      0\n0.2                                                      0\nan interview with ABC17 News                            12\ndtype: int64 \n\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(df):\n    column_names = [\"id\", \"label\", \"statement\", \"subjects\", \"speaker\",\"speaker_job\", \"state\", \"party\", \"barely_true\",\"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\", \"context\"]\n    df.columns = column_names\n    \n    df = df.select_dtypes(exclude=['number'])\n    df.fillna('unknown', inplace=True)\n    df['statement'] = 'id: ' + df['statement'] + ', context: ' + df['context'] + ', subjects: ' + df['subjects'] + ', speaker: ' + df['speaker'] + ', speaker_job: ' + df['speaker_job'] + ', state: ' + df['state'] + ', party: ' + df['party']\n    df.drop(['id', 'subjects', 'speaker', 'speaker_job', 'state', 'party', 'context'], axis=1, inplace=True)\n    df['label'] = df['label'].apply(lambda x: 1 if x in ['false', 'pants-on-fire', 'barely-true'] else 0)\n    df = df[['statement', 'label']]\n    \n    return df\n\ntrain = preprocess(train)\ntest = preprocess(test)\nvalid = preprocess(valid)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:54:45.889358Z","iopub.execute_input":"2024-11-06T16:54:45.889734Z","iopub.status.idle":"2024-11-06T16:54:45.968577Z","shell.execute_reply.started":"2024-11-06T16:54:45.889698Z","shell.execute_reply":"2024-11-06T16:54:45.967822Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing the train, test, and valid datasets by ROBERTa Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n\nMAX_LEN = 256","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:54:50.237750Z","iopub.execute_input":"2024-11-06T16:54:50.238667Z","iopub.status.idle":"2024-11-06T16:54:51.274017Z","shell.execute_reply.started":"2024-11-06T16:54:50.238623Z","shell.execute_reply":"2024-11-06T16:54:51.272916Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5bb1efa0e8481682165c9672187b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735825cccf504d1ca49a81f3423b31ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4ea38b41d440efaffe960a4cab38c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32ae7d8d60d4117960e82e75f4f2881"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc17698f861043a7a866a95b083f7013"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_data(dataset):\n    input_ids_list = []\n    attention_masks_list = []\n\n    # Encode the dataset\n    for text in tqdm(dataset['statement'].values, desc=\"Tokenizing\", unit=\"text\"):\n        encoded = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=MAX_LEN,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        input_ids_list.append(encoded['input_ids'])\n        attention_masks_list.append(encoded['attention_mask'])\n\n    input_ids = torch.cat(input_ids_list)\n    attention_masks = torch.cat(attention_masks_list)\n\n    labels = torch.tensor(dataset['label'].astype('category').cat.codes.values)\n\n    return input_ids, attention_masks, labels","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:14.835909Z","iopub.execute_input":"2024-11-06T16:55:14.836614Z","iopub.status.idle":"2024-11-06T16:55:14.843283Z","shell.execute_reply.started":"2024-11-06T16:55:14.836564Z","shell.execute_reply":"2024-11-06T16:55:14.842328Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_input_ids, train_attention_masks, train_labels = tokenize_data(train)\nvalid_input_ids, valid_attention_masks, valid_labels = tokenize_data(valid)\ntest_input_ids, test_attention_masks, test_labels = tokenize_data(test)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:17.722875Z","iopub.execute_input":"2024-11-06T16:55:17.723760Z","iopub.status.idle":"2024-11-06T16:55:29.523382Z","shell.execute_reply.started":"2024-11-06T16:55:17.723702Z","shell.execute_reply":"2024-11-06T16:55:29.522430Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Tokenizing: 100%|██████████| 10239/10239 [00:09<00:00, 1082.19text/s]\nTokenizing: 100%|██████████| 1283/1283 [00:01<00:00, 1128.56text/s]\nTokenizing: 100%|██████████| 1266/1266 [00:01<00:00, 1167.05text/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrain_input_ids, train_attention_masks, train_labels = train_input_ids.to(device), train_attention_masks.to(device), train_labels.to(device)\nvalid_input_ids, valid_attention_masks, valid_labels = valid_input_ids.to(device), valid_attention_masks.to(device), valid_labels.to(device)\ntest_input_ids, test_attention_masks, test_labels = test_input_ids.to(device), test_attention_masks.to(device), test_labels.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:37.681018Z","iopub.execute_input":"2024-11-06T16:55:37.681707Z","iopub.status.idle":"2024-11-06T16:55:37.886246Z","shell.execute_reply.started":"2024-11-06T16:55:37.681666Z","shell.execute_reply":"2024-11-06T16:55:37.885226Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Creating dataloaders","metadata":{}},{"cell_type":"code","source":"batch_size = 4\n\ntrain_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n\ntest_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:41.731595Z","iopub.execute_input":"2024-11-06T16:55:41.732090Z","iopub.status.idle":"2024-11-06T16:55:41.740141Z","shell.execute_reply.started":"2024-11-06T16:55:41.732050Z","shell.execute_reply":"2024-11-06T16:55:41.739118Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## ROBERTa model initialization","metadata":{}},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\n    'roberta-base', \n    num_labels=2, \n    output_attentions=False,\n    output_hidden_states=False\n)\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:45.008462Z","iopub.execute_input":"2024-11-06T16:55:45.009087Z","iopub.status.idle":"2024-11-06T16:55:47.676863Z","shell.execute_reply.started":"2024-11-06T16:55:45.009047Z","shell.execute_reply":"2024-11-06T16:55:47.675972Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d416422421464f5f91dfa4210271d75f"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8, weight_decay=0.01)\n\nepochs = 3\ntotal_steps = len(train_dataloader) * epochs\n\nnum_warmup_steps = int(0.1 * total_steps)  # 10% of total steps\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_warmup_steps,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:55:56.713967Z","iopub.execute_input":"2024-11-06T16:55:56.714323Z","iopub.status.idle":"2024-11-06T16:55:57.170028Z","shell.execute_reply.started":"2024-11-06T16:55:56.714290Z","shell.execute_reply":"2024-11-06T16:55:57.169004Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Training and visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:56:00.655725Z","iopub.execute_input":"2024-11-06T16:56:00.656296Z","iopub.status.idle":"2024-11-06T16:56:00.669017Z","shell.execute_reply.started":"2024-11-06T16:56:00.656259Z","shell.execute_reply":"2024-11-06T16:56:00.668155Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:56:02.367199Z","iopub.execute_input":"2024-11-06T16:56:02.367588Z","iopub.status.idle":"2024-11-06T16:56:02.372277Z","shell.execute_reply.started":"2024-11-06T16:56:02.367551Z","shell.execute_reply":"2024-11-06T16:56:02.371307Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"scaler = GradScaler()  # For mixed precision\naccumulation_steps = 4  # Number of steps for gradient accumulation\n\n# Define the total number of iterations for the progress bar\ntotal_steps = len(train_dataloader) + len(val_dataloader)\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    model.train()\n\n    total_loss = 0\n    correct_predictions = 0\n    total_train = 0\n\n    # Create a single progress bar for the entire epoch\n    pbar = tqdm(total=len(train_dataloader), desc=\"Training\")\n    \n    # Training Phase\n    for step, batch in enumerate(train_dataloader):\n        # Move the batch to the appropriate device\n        batch = tuple(b.to(device) for b in batch)\n        inputs, masks, labels = batch\n        \n        # Ensure labels are of type long (integer)\n        labels = labels.long()  # Convert labels to long type if they are not already\n\n        # Enable autocasting for mixed precision\n        with autocast():\n            outputs = model(input_ids=inputs, attention_mask=masks)  # Updated for RoBERTa\n            logits = outputs.logits\n            \n            # CrossEntropyLoss expects labels to be in the shape [batch_size] and integers\n            loss = torch.nn.functional.cross_entropy(logits, labels)  # Use Cross Entropy Loss\n            \n        # Accumulate loss\n        total_loss += loss.item()\n\n        # Calculate training accuracy\n        predictions = torch.argmax(logits, dim=-1)\n        correct_predictions += (predictions == labels).sum().item()\n        total_train += labels.size(0)\n\n        # Scale the loss and call backward() to create the gradients\n        scaler.scale(loss).backward()\n        \n        # Update weights after accumulating gradients\n        if (step + 1) % accumulation_steps == 0 or step == len(train_dataloader) - 1:\n            # Clip gradients to prevent explosion\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer)  # Update model parameters\n            scaler.update()         # Update the scaler for the next iteration\n            optimizer.zero_grad()   # Clear gradients for the next step\n\n        # Update progress bar for training\n        pbar.update(1)  # Increment progress bar\n    pbar.close()\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    avg_train_accuracy = correct_predictions / total_train\n    train_losses.append(avg_train_loss)\n    train_accuracies.append(avg_train_accuracy)\n\n    print(f'Average training loss: {avg_train_loss:.2f}')\n    print(f'Training accuracy: {avg_train_accuracy:.2f}')\n\n    # Evaluation Phase\n    model.eval()\n    eval_loss = 0\n    correct_predictions_val = 0\n    total_val = 0\n\n    # Evaluate without gradient tracking\n    with torch.no_grad():\n        for batch in val_dataloader:\n            batch = tuple(b.to(device) for b in batch)\n            inputs, masks, labels = batch\n\n            # Ensure labels are of type long (integer)\n            labels = labels.long()  # Convert labels to long type if they are not already\n            \n            outputs = model(input_ids=inputs, attention_mask=masks) \n            logits = outputs.logits\n            eval_loss += torch.nn.functional.cross_entropy(logits, labels).item()  # Use Cross Entropy Loss\n\n            # Calculate validation accuracy\n            predictions = torch.argmax(logits, dim=-1)\n            correct_predictions_val += (predictions == labels).sum().item()\n            total_val += labels.size(0)\n\n    avg_val_loss = eval_loss / len(val_dataloader)\n    avg_val_accuracy = correct_predictions_val / total_val\n    val_losses.append(avg_val_loss)\n    val_accuracies.append(avg_val_accuracy)\n\n    print(f'Validation Loss: {avg_val_loss:.2f}')\n    print(f'Validation Accuracy: {avg_val_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T16:56:04.708388Z","iopub.execute_input":"2024-11-06T16:56:04.708767Z","iopub.status.idle":"2024-11-06T17:05:36.471439Z","shell.execute_reply.started":"2024-11-06T16:56:04.708730Z","shell.execute_reply":"2024-11-06T17:05:36.470493Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/766884999.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # For mixed precision\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/2560 [00:00<?, ?it/s]/tmp/ipykernel_30/766884999.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nTraining: 100%|██████████| 2560/2560 [02:52<00:00, 14.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.66\nTraining accuracy: 0.62\nValidation Loss: 0.67\nValidation Accuracy: 0.61\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2560/2560 [02:53<00:00, 14.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.66\nTraining accuracy: 0.62\nValidation Loss: 0.67\nValidation Accuracy: 0.61\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2560/2560 [02:53<00:00, 14.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 0.67\nTraining accuracy: 0.61\nValidation Loss: 0.67\nValidation Accuracy: 0.61\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\n\nmodel.eval()  # Set model to evaluation mode\ntest_loss = 0\ncorrect_predictions_test = 0\ntotal_test = 0\ntest_predictions_all = []\ntest_true_labels_all = []\n\n# Evaluate on the test set without gradient tracking\nfor batch in test_dataloader:\n    batch = tuple(b.to(device) for b in batch)\n    inputs, masks, labels = batch\n\n    # Ensure labels are long type for CrossEntropyLoss\n    labels = labels.long()\n\n    with torch.no_grad():\n        # Get model outputs (logits)\n        outputs = model(input_ids=inputs, attention_mask=masks)\n        \n        logits = outputs.logits\n        \n        # Calculate loss using CrossEntropyLoss\n        loss = criterion(logits, labels)\n        test_loss += loss.item() \n\n    # Calculate test accuracy\n    predictions = torch.argmax(logits, dim=-1)\n    correct_predictions_test += (predictions == labels).sum().item()\n    total_test += labels.size(0)\n\n    test_predictions_all.extend(predictions.cpu().numpy())\n    test_true_labels_all.extend(labels.cpu().numpy())\n\n# Calculate average test loss and accuracy\navg_test_loss = test_loss / len(test_dataloader)\navg_test_accuracy = correct_predictions_test / total_test\n\nprint(f'Test Loss: {avg_test_loss:.2f}')\nprint(f'Test Accuracy: {avg_test_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:05:43.686584Z","iopub.execute_input":"2024-11-06T17:05:43.687440Z","iopub.status.idle":"2024-11-06T17:06:00.984359Z","shell.execute_reply.started":"2024-11-06T17:05:43.687395Z","shell.execute_reply":"2024-11-06T17:06:00.983092Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Test Loss: 0.66\nTest Accuracy: 0.64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\nClassification Report:\")\nprint(classification_report(test_true_labels_all, test_predictions_all))\n\nroc_auc = roc_auc_score(test_true_labels_all, test_predictions_all)\nprint(f'ROC-AUC Score: {roc_auc:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:06:00.986065Z","iopub.execute_input":"2024-11-06T17:06:00.986354Z","iopub.status.idle":"2024-11-06T17:06:01.011436Z","shell.execute_reply.started":"2024-11-06T17:06:00.986322Z","shell.execute_reply":"2024-11-06T17:06:01.010606Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.64      1.00      0.78       805\n           1       0.00      0.00      0.00       461\n\n    accuracy                           0.64      1266\n   macro avg       0.32      0.50      0.39      1266\nweighted avg       0.40      0.64      0.49      1266\n\nROC-AUC Score: 0.50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"import plotly.graph_objs as go\n\nfig = go.Figure()\n\n# Loss traces\nfig.add_trace(go.Scatter(\n    x=list(range(1, epochs + 1)),y=train_losses,mode='lines+markers',name='Training Loss',line=dict(color='blue', width=2),marker=dict(size=5)\n))\n\nfig.add_trace(go.Scatter(\n    x=list(range(1, epochs + 1)),y=val_losses,mode='lines+markers',name='Validation Loss',line=dict(color='orange', width=2),marker=dict(size=5)\n))\n\n# Accuracy traces\nfig.add_trace(go.Scatter(\n    x=list(range(1, epochs + 1)),y=train_accuracies,mode='lines+markers',name='Training Accuracy',line=dict(color='green', width=2),marker=dict(size=5)\n))\n\nfig.add_trace(go.Scatter(\n    x=list(range(1, epochs + 1)),y=val_accuracies,mode='lines+markers',name='Validation Accuracy',line=dict(color='red', width=2),marker=dict(size=5)\n))\n\n# Update layout\nfig.update_layout(\n    title='Training and Validation Loss and Accuracy',xaxis_title='Epochs',yaxis_title='Loss',legend_title='Metrics',yaxis=dict(title='Loss', titlefont=dict(color='blue'), tickfont=dict(color='blue')),yaxis2=dict(title='Accuracy', titlefont=dict(color='green'), tickfont=dict(color='green'), overlaying='y', side='right'),showlegend=True\n)\n\n# Update the y-axis for accuracy\nfig.update_traces(yaxis='y', selector=dict(name='Training Accuracy'))\nfig.update_traces(yaxis='y', selector=dict(name='Validation Accuracy'))\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:06:01.012680Z","iopub.execute_input":"2024-11-06T17:06:01.012982Z","iopub.status.idle":"2024-11-06T17:06:01.470306Z","shell.execute_reply.started":"2024-11-06T17:06:01.012951Z","shell.execute_reply":"2024-11-06T17:06:01.469443Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"e0f569fd-9837-490a-8837-c69dae6aa017\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e0f569fd-9837-490a-8837-c69dae6aa017\")) {                    Plotly.newPlot(                        \"e0f569fd-9837-490a-8837-c69dae6aa017\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"marker\":{\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Training Loss\",\"x\":[1,2,3],\"y\":[0.6646579027175903,0.664778208732605,0.6674148003337905],\"type\":\"scatter\"},{\"line\":{\"color\":\"orange\",\"width\":2},\"marker\":{\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Validation Loss\",\"x\":[1,2,3],\"y\":[0.6718593451464288,0.6718593451464288,0.6718593451464288],\"type\":\"scatter\"},{\"line\":{\"color\":\"green\",\"width\":2},\"marker\":{\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Training Accuracy\",\"x\":[1,2,3],\"y\":[0.6207637464596152,0.616661783377283,0.6089461861509913],\"type\":\"scatter\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":2},\"marker\":{\"size\":5},\"mode\":\"lines+markers\",\"name\":\"Validation Accuracy\",\"x\":[1,2,3],\"y\":[0.6110678098207326,0.6110678098207326,0.6110678098207326],\"type\":\"scatter\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Loss\",\"font\":{\"color\":\"blue\"}},\"tickfont\":{\"color\":\"blue\"}},\"yaxis2\":{\"title\":{\"text\":\"Accuracy\",\"font\":{\"color\":\"green\"}},\"tickfont\":{\"color\":\"green\"},\"overlaying\":\"y\",\"side\":\"right\"},\"title\":{\"text\":\"Training and Validation Loss and Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"legend\":{\"title\":{\"text\":\"Metrics\"}},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('e0f569fd-9837-490a-8837-c69dae6aa017');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\nsave_directory = \"/kaggle/working/roberta-liar-binary\"\nos.makedirs(save_directory, exist_ok=True)\n\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\n\nzip_file_path = \"/kaggle/working/roberta-liar-binary.zip\"\nshutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-11-06T17:08:00.901516Z","iopub.execute_input":"2024-11-06T17:08:00.902503Z","iopub.status.idle":"2024-11-06T17:10:00.581724Z","shell.execute_reply.started":"2024-11-06T17:08:00.902457Z","shell.execute_reply":"2024-11-06T17:10:00.580794Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/roberta-liar-binary.zip'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}